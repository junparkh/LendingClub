{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\genie\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\genie\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\genie\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pickle data and define X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stockdf = pd.read_pickle(\"035720.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = stockdf.등락률[:-1]\n",
    "x_data = stockdf.iloc[:,stockdf.columns != '등락률'][1:]\n",
    "x_data = x_data.drop('날짜',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test 0.75 : 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>등락률</th>\n",
       "      <th>기관 순매매량</th>\n",
       "      <th>외국인 순매매량</th>\n",
       "      <th>외국인 보유율</th>\n",
       "      <th>종가</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>거래량</th>\n",
       "      <th>기간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>등락률</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.219724</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>0.023653</td>\n",
       "      <td>-0.079063</td>\n",
       "      <td>-0.029506</td>\n",
       "      <td>-0.030781</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>-0.059190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기관 순매매량</th>\n",
       "      <td>0.496914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062476</td>\n",
       "      <td>0.043178</td>\n",
       "      <td>0.159250</td>\n",
       "      <td>0.108997</td>\n",
       "      <td>0.131259</td>\n",
       "      <td>0.135362</td>\n",
       "      <td>0.222434</td>\n",
       "      <td>0.044224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>외국인 순매매량</th>\n",
       "      <td>0.219724</td>\n",
       "      <td>-0.062476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>-0.156282</td>\n",
       "      <td>-0.185715</td>\n",
       "      <td>-0.176292</td>\n",
       "      <td>-0.171103</td>\n",
       "      <td>-0.081782</td>\n",
       "      <td>-0.092361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>외국인 보유율</th>\n",
       "      <td>0.013221</td>\n",
       "      <td>0.043178</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301238</td>\n",
       "      <td>0.294684</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.302273</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.229043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>종가</th>\n",
       "      <td>0.023653</td>\n",
       "      <td>0.159250</td>\n",
       "      <td>-0.156282</td>\n",
       "      <td>0.301238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993112</td>\n",
       "      <td>0.997047</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.303791</td>\n",
       "      <td>0.525714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시가</th>\n",
       "      <td>-0.079063</td>\n",
       "      <td>0.108997</td>\n",
       "      <td>-0.185715</td>\n",
       "      <td>0.294684</td>\n",
       "      <td>0.993112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.305055</td>\n",
       "      <td>0.524669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고가</th>\n",
       "      <td>-0.029506</td>\n",
       "      <td>0.131259</td>\n",
       "      <td>-0.176292</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.997047</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>0.325991</td>\n",
       "      <td>0.525593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저가</th>\n",
       "      <td>-0.030781</td>\n",
       "      <td>0.135362</td>\n",
       "      <td>-0.171103</td>\n",
       "      <td>0.302273</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.997340</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285294</td>\n",
       "      <td>0.527528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래량</th>\n",
       "      <td>-0.006049</td>\n",
       "      <td>0.222434</td>\n",
       "      <td>-0.081782</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.303791</td>\n",
       "      <td>0.305055</td>\n",
       "      <td>0.325991</td>\n",
       "      <td>0.285294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기간</th>\n",
       "      <td>-0.059190</td>\n",
       "      <td>0.044224</td>\n",
       "      <td>-0.092361</td>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.524669</td>\n",
       "      <td>0.525593</td>\n",
       "      <td>0.527528</td>\n",
       "      <td>-0.066279</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               등락률   기관 순매매량  외국인 순매매량   외국인 보유율        종가        시가  \\\n",
       "등락률       1.000000  0.496914  0.219724  0.013221  0.023653 -0.079063   \n",
       "기관 순매매량   0.496914  1.000000 -0.062476  0.043178  0.159250  0.108997   \n",
       "외국인 순매매량  0.219724 -0.062476  1.000000  0.064913 -0.156282 -0.185715   \n",
       "외국인 보유율   0.013221  0.043178  0.064913  1.000000  0.301238  0.294684   \n",
       "종가        0.023653  0.159250 -0.156282  0.301238  1.000000  0.993112   \n",
       "시가       -0.079063  0.108997 -0.185715  0.294684  0.993112  1.000000   \n",
       "고가       -0.029506  0.131259 -0.176292  0.295340  0.997047  0.997313   \n",
       "저가       -0.030781  0.135362 -0.171103  0.302273  0.997093  0.997340   \n",
       "거래량      -0.006049  0.222434 -0.081782  0.113947  0.303791  0.305055   \n",
       "기간       -0.059190  0.044224 -0.092361  0.229043  0.525714  0.524669   \n",
       "\n",
       "                고가        저가       거래량        기간  \n",
       "등락률      -0.029506 -0.030781 -0.006049 -0.059190  \n",
       "기관 순매매량   0.131259  0.135362  0.222434  0.044224  \n",
       "외국인 순매매량 -0.176292 -0.171103 -0.081782 -0.092361  \n",
       "외국인 보유율   0.295340  0.302273  0.113947  0.229043  \n",
       "종가        0.997047  0.997093  0.303791  0.525714  \n",
       "시가        0.997313  0.997340  0.305055  0.524669  \n",
       "고가        1.000000  0.997122  0.325991  0.525593  \n",
       "저가        0.997122  1.000000  0.285294  0.527528  \n",
       "거래량       0.325991  0.285294  1.000000 -0.066279  \n",
       "기간        0.525593  0.527528 -0.066279  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockdf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1575725593667546"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a544b7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_data)\n",
    "y_data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train_scale = pd.DataFrame(data = scale.transform(X_train), columns = X_train.columns.tolist())\n",
    "X_test_scale = pd.DataFrame(data = scale.transform(X_test), columns = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 23 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>0.000490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:54:21</td>     <th>  Log-Likelihood:    </th> <td> -625.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   284</td>      <th>  AIC:               </th> <td>   1272.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   274</td>      <th>  BIC:               </th> <td>   1308.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.1596</td> <td>    0.132</td> <td>    1.205</td> <td> 0.229</td> <td>   -0.101</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>기관 순매매량</th>  <td>    0.6395</td> <td>    0.157</td> <td>    4.061</td> <td> 0.000</td> <td>    0.329</td> <td>    0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>외국인 순매매량</th> <td>    0.2233</td> <td>    0.142</td> <td>    1.574</td> <td> 0.117</td> <td>   -0.056</td> <td>    0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>외국인 보유율</th>  <td>    0.1007</td> <td>    0.143</td> <td>    0.706</td> <td> 0.480</td> <td>   -0.180</td> <td>    0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>종가</th>       <td>   -2.6087</td> <td>    2.687</td> <td>   -0.971</td> <td> 0.333</td> <td>   -7.899</td> <td>    2.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>시가</th>       <td>    5.3258</td> <td>    2.891</td> <td>    1.842</td> <td> 0.067</td> <td>   -0.366</td> <td>   11.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>고가</th>       <td>    4.4587</td> <td>    3.224</td> <td>    1.383</td> <td> 0.168</td> <td>   -1.887</td> <td>   10.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>저가</th>       <td>   -7.3169</td> <td>    3.327</td> <td>   -2.199</td> <td> 0.029</td> <td>  -13.867</td> <td>   -0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>거래량</th>      <td>   -0.6039</td> <td>    0.188</td> <td>   -3.204</td> <td> 0.002</td> <td>   -0.975</td> <td>   -0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>기간</th>       <td>   -0.2117</td> <td>    0.165</td> <td>   -1.286</td> <td> 0.199</td> <td>   -0.536</td> <td>    0.112</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>21.906</td> <th>  Durbin-Watson:     </th> <td>   1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  42.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.417</td> <th>  Prob(JB):          </th> <td>5.79e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.703</td> <th>  Cond. No.          </th> <td>    79.8</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.102\n",
       "Model:                            OLS   Adj. R-squared:                  0.072\n",
       "Method:                 Least Squares   F-statistic:                     3.442\n",
       "Date:                Sun, 23 Sep 2018   Prob (F-statistic):           0.000490\n",
       "Time:                        15:54:21   Log-Likelihood:                -625.99\n",
       "No. Observations:                 284   AIC:                             1272.\n",
       "Df Residuals:                     274   BIC:                             1308.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.1596      0.132      1.205      0.229      -0.101       0.420\n",
       "기관 순매매량        0.6395      0.157      4.061      0.000       0.329       0.950\n",
       "외국인 순매매량       0.2233      0.142      1.574      0.117      -0.056       0.503\n",
       "외국인 보유율        0.1007      0.143      0.706      0.480      -0.180       0.381\n",
       "종가            -2.6087      2.687     -0.971      0.333      -7.899       2.682\n",
       "시가             5.3258      2.891      1.842      0.067      -0.366      11.017\n",
       "고가             4.4587      3.224      1.383      0.168      -1.887      10.805\n",
       "저가            -7.3169      3.327     -2.199      0.029     -13.867      -0.767\n",
       "거래량           -0.6039      0.188     -3.204      0.002      -0.975      -0.233\n",
       "기간            -0.2117      0.165     -1.286      0.199      -0.536       0.112\n",
       "==============================================================================\n",
       "Omnibus:                       21.906   Durbin-Watson:                   1.922\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.540\n",
       "Skew:                           0.417   Prob(JB):                     5.79e-10\n",
       "Kurtosis:                       4.703   Cond. No.                         79.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_scale_add = sm.add_constant(X_train_scale)\n",
    "X_test_scale_add = sm.add_constant(X_test_scale)\n",
    "y_train_re = y_train.values.reshape(-1,1)\n",
    "y_test_re = y_test.values.reshape(-1,1)\n",
    "OLSmodel = OLS(y_train_re,X_train_scale_add).fit()\n",
    "OLSmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.07109139938631515\n",
      "mean of profit : 0.2194733497919889\n"
     ]
    }
   ],
   "source": [
    "yhat = OLSmodel.predict(X_test_scale_add)\n",
    "print(\"rscore {0}\".format(r2_score(y_test,yhat)))\n",
    "print(\"mean of profit : {0}\".format(OLSmodel.predict(X_test_scale_add).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model, Ridge and Lasso (cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.07109139938631515\n",
      "mean of profit : 0.2194733497919909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'거래량': -0.6038838995727712,\n",
       " '고가': 4.45868209913728,\n",
       " '기간': -0.21170919940580074,\n",
       " '기관 순매매량': 0.6395089187823471,\n",
       " '시가': 5.325824356076458,\n",
       " '외국인 보유율': 0.10069299291096899,\n",
       " '외국인 순매매량': 0.22329197425159242,\n",
       " '저가': -7.316880447576435,\n",
       " '종가': -2.6086563036863426}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearmodel = LinearRegression().fit(X_train_scale,y_train)\n",
    "print(\"rscore {0}\".format(linearmodel.score(X_test_scale,y_test)))\n",
    "print(\"mean of profit : {0}\".format(linearmodel.predict(X_test_scale).mean()))\n",
    "{k: v for k,v in zip(X_train_scale.columns, linearmodel.coef_.ravel())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.06383842341159385\n",
      "mean of profit : 0.2184031264810883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'거래량': -0.5473516959723668,\n",
       " '고가': 3.9488675476305275,\n",
       " '기간': -0.200121211736203,\n",
       " '기관 순매매량': 0.6082480241593657,\n",
       " '시가': 4.428783899866573,\n",
       " '외국인 보유율': 0.08760505784208306,\n",
       " '외국인 순매매량': 0.208565486086826,\n",
       " '저가': -5.798970438925409,\n",
       " '종가': -2.738981804256696}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge = RidgeCV().fit(X_train_scale,y_train)\n",
    "print(\"rscore {0}\".format(Ridge.score(X_test_scale,y_test)))\n",
    "print(\"mean of profit : {0}\".format(Ridge.predict(X_test_scale).mean()))\n",
    "{k: v for k,v in zip(X_train_scale.columns, Ridge.coef_.ravel())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\genie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.06348231928402615\n",
      "mean of profit : 0.2152486906666355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\genie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "Lassomodel = LassoCV().fit(X_train_scale,y_train)\n",
    "print(\"rscore {0}\".format(Lassomodel.score(X_test_scale,y_test)))\n",
    "print(\"mean of profit : {0}\".format(Lassomodel.predict(X_test_scale).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.17408631428171706\n",
      "mean of profit : 0.39172631578947376\n"
     ]
    }
   ],
   "source": [
    "RandomRegression = RandomForestRegressor().fit(X_train_scale,y_train)\n",
    "print(\"rscore {0}\".format(RandomRegression.score(X_test_scale,y_test)))\n",
    "print(\"mean of profit : {0}\".format(RandomRegression.predict(X_test_scale).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.07109139938631515\n",
      "mean of profit : 0.2194733497919909\n"
     ]
    }
   ],
   "source": [
    "Adaregressor = AdaBoostRegressor().fit(X_train_scale,y_train)\n",
    "print(\"rscore {0}\".format(linearmodel.score(X_test_scale,y_test)))\n",
    "print(\"mean of profit : {0}\".format(linearmodel.predict(X_test_scale).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_strategy(model, df, profit, cutoff=None, showprint=True):\n",
    "    # see where our model says to invest\n",
    "    inv = model.predict(df)\n",
    "    if cutoff is not None: \n",
    "        inv = inv > cutoff\n",
    "        inv = inv.reshape(-1)\n",
    "    # return the mean return\n",
    "    if showprint:\n",
    "        print(\"Positive result on %d out of %d (%0.2f%%)\" % (inv.sum(), inv.shape[0], inv.sum() / inv.shape[0] * 100.0))\n",
    "        print(\"Mean return of strategy:\", profit[inv].mean())\n",
    "        print(\"Overall return:\", profit.mean())\n",
    "    return profit[inv].mean(), profit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_cat = y_train > 0\n",
    "y_test_cat = y_test >0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4631578947368421\n",
      "Positive result on 34 out of 95 (35.79%)\n",
      "Mean return of strategy: -0.2958823529411765\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.2958823529411765, 0.15147368421052626)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist =LogisticRegressionCV().fit(X_train_scale, y_train_cat)\n",
    "print(accuracy_score(y_test_cat,Logist.predict(X_test_scale)))\n",
    "evaluate_strategy(Logist,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5157894736842106\n",
      "Positive result on 43 out of 95 (45.26%)\n",
      "Mean return of strategy: 0.31837209302325603\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31837209302325603, 0.15147368421052626)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decision = DecisionTreeClassifier().fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,Decision.predict(X_test_scale)))\n",
    "evaluate_strategy(Decision,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45263157894736844\n",
      "Positive result on 31 out of 95 (32.63%)\n",
      "Mean return of strategy: -0.3212903225806451\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.3212903225806451, 0.15147368421052626)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier().fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,RandomForest.predict(X_test_scale)))\n",
    "evaluate_strategy(RandomForest,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5473684210526316\n",
      "Positive result on 44 out of 95 (46.32%)\n",
      "Mean return of strategy: 0.384090909090909\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.384090909090909, 0.15147368421052626)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaCL = AdaBoostClassifier(n_estimators=300,learning_rate=0.05).fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,AdaCL.predict(X_test_scale)))\n",
    "evaluate_strategy(AdaCL,X_test_scale,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding polynomial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(4)\n",
    "X_train_poly = poly.fit_transform(X_train_scale)\n",
    "X_test_poly = poly.fit_transform(X_test_scale)\n",
    "\n",
    "newscaler = StandardScaler().fit(X_train_poly)\n",
    "\n",
    "X_train_poly = newscaler.transform(X_train_poly)\n",
    "X_test_poly = newscaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052631578947369\n",
      "Positive result on 24 out of 95 (25.26%)\n",
      "Mean return of strategy: -0.017499999999999977\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.017499999999999977, 0.15147368421052626)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polylog = LogisticRegressionCV().fit(X_train_poly,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,polylog.predict(X_test_poly)))\n",
    "evaluate_strategy(polylog,X_test_poly,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscore -0.43888142621803516\n",
      "mean of profit : 0.20308272760436602\n"
     ]
    }
   ],
   "source": [
    "polyridge = RidgeCV().fit(X_train_poly,y_train)\n",
    "print(\"rscore {0}\".format(polyridge.score(X_test_poly,y_test)))\n",
    "print(\"mean of profit : {0}\".format(polyridge.predict(X_test_poly).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM, LDA, QDA, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4842105263157895\n",
      "Positive result on 44 out of 95 (46.32%)\n",
      "Mean return of strategy: -0.023409090909090945\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.023409090909090945, 0.15147368421052626)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC().fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,SVM.predict(X_test_scale)))\n",
    "evaluate_strategy(SVM,X_test_scale,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5684210526315789\n",
      "Positive result on 42 out of 95 (44.21%)\n",
      "Mean return of strategy: 0.4285714285714287\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4285714285714287, 0.15147368421052626)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA =LinearDiscriminantAnalysis().fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,LDA.predict(X_test_scale)))\n",
    "evaluate_strategy(LDA,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052631578947369\n",
      "Positive result on 32 out of 95 (33.68%)\n",
      "Mean return of strategy: 0.13468750000000002\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13468750000000002, 0.15147368421052626)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis().fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,QDA.predict(X_test_scale)))\n",
    "evaluate_strategy(QDA,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5578947368421052\n",
      "Positive result on 57 out of 95 (60.00%)\n",
      "Mean return of strategy: 0.38982456140350896\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38982456140350896, 0.15147368421052626)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5).fit(X_train_scale,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,KNN.predict(X_test_scale)))\n",
    "evaluate_strategy(KNN,X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network, Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 715)               511940    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               358000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,089,307\n",
      "Trainable params: 1,089,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(715, input_dim=X_train_poly.shape[1], activation='relu'))\n",
    "model_nn.add(Dense(500, activation='relu'))\n",
    "model_nn.add(Dense(300, activation='relu'))\n",
    "model_nn.add(Dense(150, activation='relu'))\n",
    "model_nn.add(Dense(100, activation='relu'))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(8, activation='relu'))\n",
    "model_nn.add(Dense(1, activation='linear'))\n",
    "model_nn.compile(loss='mse', optimizer='adam')\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples, validate on 57 samples\n",
      "Epoch 1/50\n",
      "227/227 [==============================] - 1s 5ms/step - loss: 0.5928 - val_loss: 0.3945\n",
      "Epoch 2/50\n",
      "227/227 [==============================] - 0s 338us/step - loss: 0.5068 - val_loss: 0.3751\n",
      "Epoch 3/50\n",
      "227/227 [==============================] - 0s 309us/step - loss: 0.3021 - val_loss: 0.3761\n",
      "Epoch 4/50\n",
      "227/227 [==============================] - 0s 278us/step - loss: 0.2899 - val_loss: 0.3691\n",
      "Epoch 5/50\n",
      "227/227 [==============================] - 0s 289us/step - loss: 0.2671 - val_loss: 0.2972\n",
      "Epoch 6/50\n",
      "227/227 [==============================] - 0s 287us/step - loss: 0.2382 - val_loss: 0.2704\n",
      "Epoch 7/50\n",
      "227/227 [==============================] - 0s 256us/step - loss: 0.2411 - val_loss: 0.2964\n",
      "Epoch 8/50\n",
      "227/227 [==============================] - 0s 294us/step - loss: 0.2190 - val_loss: 0.3025\n",
      "Epoch 9/50\n",
      "227/227 [==============================] - 0s 266us/step - loss: 0.2164 - val_loss: 0.3196\n",
      "Epoch 10/50\n",
      "227/227 [==============================] - 0s 294us/step - loss: 0.2100 - val_loss: 0.3282\n",
      "Epoch 11/50\n",
      "227/227 [==============================] - 0s 277us/step - loss: 0.2059 - val_loss: 0.3010\n",
      "Epoch 12/50\n",
      "227/227 [==============================] - 0s 277us/step - loss: 0.1992 - val_loss: 0.2930\n",
      "Epoch 13/50\n",
      "227/227 [==============================] - 0s 293us/step - loss: 0.2000 - val_loss: 0.2769\n",
      "Epoch 14/50\n",
      "227/227 [==============================] - 0s 273us/step - loss: 0.2178 - val_loss: 0.4300\n",
      "Epoch 15/50\n",
      "227/227 [==============================] - 0s 270us/step - loss: 0.2766 - val_loss: 0.2897\n",
      "Epoch 16/50\n",
      "227/227 [==============================] - 0s 284us/step - loss: 0.1957 - val_loss: 0.2926\n",
      "Epoch 17/50\n",
      "227/227 [==============================] - 0s 271us/step - loss: 0.2323 - val_loss: 0.3032\n",
      "Epoch 18/50\n",
      "227/227 [==============================] - 0s 259us/step - loss: 0.1882 - val_loss: 0.3486\n",
      "Epoch 19/50\n",
      "227/227 [==============================] - 0s 288us/step - loss: 0.2187 - val_loss: 0.2995\n",
      "Epoch 20/50\n",
      "227/227 [==============================] - 0s 250us/step - loss: 0.1786 - val_loss: 0.2882\n",
      "Epoch 21/50\n",
      "227/227 [==============================] - 0s 317us/step - loss: 0.2060 - val_loss: 0.2928\n",
      "Epoch 22/50\n",
      "227/227 [==============================] - 0s 286us/step - loss: 0.1750 - val_loss: 0.3264\n",
      "Epoch 23/50\n",
      "227/227 [==============================] - 0s 265us/step - loss: 0.1900 - val_loss: 0.3036\n",
      "Epoch 24/50\n",
      "227/227 [==============================] - 0s 284us/step - loss: 0.1751 - val_loss: 0.2852\n",
      "Epoch 25/50\n",
      "227/227 [==============================] - 0s 261us/step - loss: 0.1750 - val_loss: 0.2833\n",
      "Epoch 26/50\n",
      "227/227 [==============================] - 0s 284us/step - loss: 0.1734 - val_loss: 0.3078\n",
      "Epoch 27/50\n",
      "227/227 [==============================] - 0s 299us/step - loss: 0.1640 - val_loss: 0.3267\n",
      "Epoch 28/50\n",
      "227/227 [==============================] - 0s 266us/step - loss: 0.1684 - val_loss: 0.3027\n",
      "Epoch 29/50\n",
      "227/227 [==============================] - 0s 273us/step - loss: 0.1564 - val_loss: 0.3009\n",
      "Epoch 30/50\n",
      "227/227 [==============================] - 0s 258us/step - loss: 0.1637 - val_loss: 0.2983\n",
      "Epoch 31/50\n",
      "227/227 [==============================] - 0s 290us/step - loss: 0.1518 - val_loss: 0.3150\n",
      "Epoch 32/50\n",
      "227/227 [==============================] - 0s 303us/step - loss: 0.1575 - val_loss: 0.3111\n",
      "Epoch 33/50\n",
      "227/227 [==============================] - 0s 256us/step - loss: 0.1466 - val_loss: 0.3122\n",
      "Epoch 34/50\n",
      "227/227 [==============================] - 0s 279us/step - loss: 0.1513 - val_loss: 0.3109\n",
      "Epoch 35/50\n",
      "227/227 [==============================] - 0s 282us/step - loss: 0.1415 - val_loss: 0.3148\n",
      "Epoch 36/50\n",
      "227/227 [==============================] - 0s 245us/step - loss: 0.1450 - val_loss: 0.3041\n",
      "Epoch 37/50\n",
      "227/227 [==============================] - 0s 278us/step - loss: 0.1361 - val_loss: 0.3051\n",
      "Epoch 38/50\n",
      "227/227 [==============================] - 0s 258us/step - loss: 0.1395 - val_loss: 0.3130\n",
      "Epoch 39/50\n",
      "227/227 [==============================] - 0s 280us/step - loss: 0.1311 - val_loss: 0.3222\n",
      "Epoch 40/50\n",
      "227/227 [==============================] - 0s 290us/step - loss: 0.1324 - val_loss: 0.3185\n",
      "Epoch 41/50\n",
      "227/227 [==============================] - 0s 294us/step - loss: 0.1272 - val_loss: 0.3246\n",
      "Epoch 42/50\n",
      "227/227 [==============================] - 0s 293us/step - loss: 0.1238 - val_loss: 0.3401\n",
      "Epoch 43/50\n",
      "227/227 [==============================] - 0s 287us/step - loss: 0.1250 - val_loss: 0.3414\n",
      "Epoch 44/50\n",
      "227/227 [==============================] - 0s 270us/step - loss: 0.1183 - val_loss: 0.3411\n",
      "Epoch 45/50\n",
      "227/227 [==============================] - 0s 277us/step - loss: 0.1149 - val_loss: 0.3451\n",
      "Epoch 46/50\n",
      "227/227 [==============================] - 0s 272us/step - loss: 0.1169 - val_loss: 0.3507\n",
      "Epoch 47/50\n",
      "227/227 [==============================] - 0s 308us/step - loss: 0.1177 - val_loss: 0.3531\n",
      "Epoch 48/50\n",
      "227/227 [==============================] - 0s 249us/step - loss: 0.1100 - val_loss: 0.3490\n",
      "Epoch 49/50\n",
      "227/227 [==============================] - 0s 270us/step - loss: 0.1040 - val_loss: 0.3565\n",
      "Epoch 50/50\n",
      "227/227 [==============================] - 0s 292us/step - loss: 0.1029 - val_loss: 0.3716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a59ad8470>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn.fit(X_train_poly, y_train_cat, epochs=50, batch_size=715, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03551161372384115"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,model_nn.predict(X_test_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble model with \n",
    "## [\"Singletree\",'RF', 'Ada', 'Logit', 'QDA','LDA','KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model = [\"Singletree\",'RF', 'Ada', 'Logit', 'QDA','LDA','KNN']\n",
    "model_dict = [Decision,RandomForest,AdaCL,Logist,QDA,LDA,KNN]\n",
    "tune_index_name =['train row {0}'.format(i+1) for i in range(len(X_train_scale))]\n",
    "ensemble_test_index_name =['test row {0}'.format(i+1) for i in range(len(X_test_scale))]                \n",
    "                                                                                                                                    \n",
    "#make empty dataframe with index i made\n",
    "ensemble_tune = pd.DataFrame(index=tune_index_name)\n",
    "ensemble_test = pd.DataFrame(index=ensemble_test_index_name)\n",
    "\n",
    "#make dataset with prediction.\n",
    "for n,i in zip(list_model,model_dict):\n",
    "    ensemble_tune[\"{0}'s model prediction\".format(n)] = [i[1] for i in i.predict_proba(X_train_scale)]\n",
    "    ensemble_test[\"{0}'s model prediction\".format(n)] = [i[1] for i in i.predict_proba(X_test_scale)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052631578947369\n",
      "Positive result on 42 out of 95 (44.21%)\n",
      "Mean return of strategy: 0.30547619047619057\n",
      "Overall return: 0.15147368421052626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30547619047619057, 0.15147368421052626)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamodel = LogisticRegressionCV().fit(ensemble_tune,y_train_cat)\n",
    "print(accuracy_score(y_test_cat,metamodel.predict(ensemble_test)))\n",
    "evaluate_strategy(metamodel,ensemble_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.90353714, -0.15758999, ..., -0.04015855,\n",
       "        -1.44587618,  3.41689895],\n",
       "       [ 0.        ,  1.00381798, -0.08484454, ..., -0.09884921,\n",
       "        -1.17017435,  3.30386542],\n",
       "       [ 0.        ,  0.1083779 , -0.00347045, ..., -0.20825055,\n",
       "        -0.43084144,  3.2482268 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.03039677,  0.12381803, ...,  0.61886532,\n",
       "        -2.93342008,  2.87477141],\n",
       "       [ 0.        , -0.19839827,  0.19640917, ...,  0.66582214,\n",
       "        -2.9494349 ,  2.72307878],\n",
       "       [ 0.        , -0.39994888, -0.09068912, ...,  0.26000638,\n",
       "        -2.14166126,  2.6736002 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tommorow = pd.DataFrame(data = scale.transform(x_data[0:10]), columns = X_train.columns.tolist())\n",
    "\n",
    "poly = PolynomialFeatures(4)\n",
    "\n",
    "X_tommorow_poly = poly.fit_transform(X_tommorow)\n",
    "\n",
    "X_tommorow_poly = newscaler.transform(X_tommorow_poly)\n",
    "X_tommorow_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True, False, False,  True,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_meta = pd.DataFrame(index=stockdf.날짜[0:10])\n",
    "for n,i in zip(list_model,model_dict):\n",
    "    today_meta[\"{0}'s model prediction\".format(n)] = [i[1] for i in i.predict_proba(X_tommorow)]\n",
    "metamodel.predict(today_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole result (tommorow's predicted price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_model = ['linearmodel','Lassomodel','Ridge','polyridge','RandomRegression','Adaregressor',\n",
    "        'model_nn','Logist','polylog','Decision','RandomForest','AdaCL','SVM','LDA','QDA','KNN','metamodel']\n",
    "\n",
    "all_dict = [linearmodel,Lassomodel,Ridge,polyridge,RandomRegression,Adaregressor,\n",
    "           model_nn,Logist,polylog,Decision,RandomForest,AdaCL,SVM,LDA,QDA,KNN,metamodel]\n",
    "\n",
    "Regression = ['linearmodel','Lassomodel','Ridge','polyridge','RandomRegression','Adaregressor',\n",
    "           'model_nn']\n",
    "Regression_model = [linearmodel,Lassomodel,Ridge,polyridge,RandomRegression,Adaregressor,\n",
    "           model_nn]\n",
    "\n",
    "\n",
    "Logistic = ['Logist','polylog','Decision','RandomForest','AdaCL','SVM','LDA','QDA','KNN','metamodel']\n",
    "Logistic_model = [Logist,Decision,RandomForest,AdaCL,LDA,QDA,KNN]\n",
    "Polynomial = [polyridge,model_nn,polylog]\n",
    "index = []\n",
    "\n",
    "for i in range(10):\n",
    "    index.append(\"{0}'s next day\".format(stockdf.날짜[i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = pd.DataFrame(index=index,columns=all_model)\n",
    "\n",
    "for n,i in zip(all_model,all_dict):\n",
    "    if i in Polynomial:\n",
    "        result[n] =i.predict(X_tommorow_poly)\n",
    "    elif i == metamodel:\n",
    "        result[n] =metamodel.predict(today_meta)\n",
    "    else:\n",
    "        result[n] =i.predict(X_tommorow)\n",
    "    \n",
    "result[\"mean\"] = result[Regression].mean(axis=1)\n",
    "\n",
    "result[\"percentage of true\"] = result[Logistic].mean(axis=1)\n",
    "result[\"true\"] = [0]+[i for i in y_data[0:9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linearmodel</th>\n",
       "      <th>Lassomodel</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>polyridge</th>\n",
       "      <th>RandomRegression</th>\n",
       "      <th>Adaregressor</th>\n",
       "      <th>model_nn</th>\n",
       "      <th>Logist</th>\n",
       "      <th>polylog</th>\n",
       "      <th>Decision</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaCL</th>\n",
       "      <th>SVM</th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>metamodel</th>\n",
       "      <th>mean</th>\n",
       "      <th>percentage of true</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-17 00:00:00's next day</th>\n",
       "      <td>-0.076754</td>\n",
       "      <td>-0.044036</td>\n",
       "      <td>-0.051200</td>\n",
       "      <td>0.839854</td>\n",
       "      <td>2.246</td>\n",
       "      <td>0.320948</td>\n",
       "      <td>0.188983</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.489114</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-16 00:00:00's next day</th>\n",
       "      <td>0.540397</td>\n",
       "      <td>0.495657</td>\n",
       "      <td>0.460510</td>\n",
       "      <td>1.247885</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.154662</td>\n",
       "      <td>0.161943</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-14 00:00:00's next day</th>\n",
       "      <td>0.629075</td>\n",
       "      <td>0.534262</td>\n",
       "      <td>0.533266</td>\n",
       "      <td>-0.168609</td>\n",
       "      <td>2.870</td>\n",
       "      <td>0.416437</td>\n",
       "      <td>0.708761</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-13 00:00:00's next day</th>\n",
       "      <td>1.625081</td>\n",
       "      <td>1.480283</td>\n",
       "      <td>1.547279</td>\n",
       "      <td>3.457145</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.095986</td>\n",
       "      <td>0.930660</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.265923</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 00:00:00's next day</th>\n",
       "      <td>0.966997</td>\n",
       "      <td>0.914726</td>\n",
       "      <td>0.893352</td>\n",
       "      <td>1.664099</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>1.060884</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947321</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-09 00:00:00's next day</th>\n",
       "      <td>0.954031</td>\n",
       "      <td>0.697609</td>\n",
       "      <td>0.853862</td>\n",
       "      <td>0.888623</td>\n",
       "      <td>2.420</td>\n",
       "      <td>-0.110156</td>\n",
       "      <td>0.267867</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.853119</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 00:00:00's next day</th>\n",
       "      <td>-0.141915</td>\n",
       "      <td>-0.148124</td>\n",
       "      <td>-0.204662</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>0.320948</td>\n",
       "      <td>0.375717</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.074718</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07 00:00:00's next day</th>\n",
       "      <td>0.036538</td>\n",
       "      <td>0.091946</td>\n",
       "      <td>0.073597</td>\n",
       "      <td>-0.240539</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.235370</td>\n",
       "      <td>1.026124</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.286577</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06 00:00:00's next day</th>\n",
       "      <td>-0.451534</td>\n",
       "      <td>-0.318611</td>\n",
       "      <td>-0.362734</td>\n",
       "      <td>-0.515505</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.164880</td>\n",
       "      <td>0.856587</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.059702</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 00:00:00's next day</th>\n",
       "      <td>0.272946</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>0.274485</td>\n",
       "      <td>-0.640060</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-0.258947</td>\n",
       "      <td>0.376105</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                linearmodel  Lassomodel     Ridge  polyridge  \\\n",
       "2018-08-17 00:00:00's next day    -0.076754   -0.044036 -0.051200   0.839854   \n",
       "2018-08-16 00:00:00's next day     0.540397    0.495657  0.460510   1.247885   \n",
       "2018-08-14 00:00:00's next day     0.629075    0.534262  0.533266  -0.168609   \n",
       "2018-08-13 00:00:00's next day     1.625081    1.480283  1.547279   3.457145   \n",
       "2018-08-10 00:00:00's next day     0.966997    0.914726  0.893352   1.664099   \n",
       "2018-08-09 00:00:00's next day     0.954031    0.697609  0.853862   0.888623   \n",
       "2018-08-08 00:00:00's next day    -0.141915   -0.148124 -0.204662   0.046012   \n",
       "2018-08-07 00:00:00's next day     0.036538    0.091946  0.073597  -0.240539   \n",
       "2018-08-06 00:00:00's next day    -0.451534   -0.318611 -0.362734  -0.515505   \n",
       "2018-08-03 00:00:00's next day     0.272946    0.088939  0.274485  -0.640060   \n",
       "\n",
       "                                RandomRegression  Adaregressor  model_nn  \\\n",
       "2018-08-17 00:00:00's next day             2.246      0.320948  0.188983   \n",
       "2018-08-16 00:00:00's next day             0.720      0.154662  0.161943   \n",
       "2018-08-14 00:00:00's next day             2.870      0.416437  0.708761   \n",
       "2018-08-13 00:00:00's next day            -0.083     -0.095986  0.930660   \n",
       "2018-08-10 00:00:00's next day             0.856      0.275185  1.060884   \n",
       "2018-08-09 00:00:00's next day             2.420     -0.110156  0.267867   \n",
       "2018-08-08 00:00:00's next day            -0.771      0.320948  0.375717   \n",
       "2018-08-07 00:00:00's next day             0.783      0.235370  1.026124   \n",
       "2018-08-06 00:00:00's next day             0.209      0.164880  0.856587   \n",
       "2018-08-03 00:00:00's next day             0.171     -0.258947  0.376105   \n",
       "\n",
       "                                Logist  polylog  Decision  RandomForest  \\\n",
       "2018-08-17 00:00:00's next day   False    False     False         False   \n",
       "2018-08-16 00:00:00's next day   False    False     False         False   \n",
       "2018-08-14 00:00:00's next day   False    False      True          True   \n",
       "2018-08-13 00:00:00's next day    True     True      True         False   \n",
       "2018-08-10 00:00:00's next day    True     True      True          True   \n",
       "2018-08-09 00:00:00's next day   False    False     False         False   \n",
       "2018-08-08 00:00:00's next day   False    False     False         False   \n",
       "2018-08-07 00:00:00's next day   False    False      True         False   \n",
       "2018-08-06 00:00:00's next day   False    False      True          True   \n",
       "2018-08-03 00:00:00's next day   False    False     False         False   \n",
       "\n",
       "                                AdaCL    SVM    LDA    QDA    KNN  metamodel  \\\n",
       "2018-08-17 00:00:00's next day  False  False  False  False   True      False   \n",
       "2018-08-16 00:00:00's next day  False  False  False  False   True      False   \n",
       "2018-08-14 00:00:00's next day  False  False  False  False  False       True   \n",
       "2018-08-13 00:00:00's next day   True   True   True   True  False       True   \n",
       "2018-08-10 00:00:00's next day   True  False   True   True  False       True   \n",
       "2018-08-09 00:00:00's next day  False  False   True   True   True      False   \n",
       "2018-08-08 00:00:00's next day  False  False  False  False   True      False   \n",
       "2018-08-07 00:00:00's next day  False  False  False  False   True       True   \n",
       "2018-08-06 00:00:00's next day   True  False  False  False  False       True   \n",
       "2018-08-03 00:00:00's next day  False  False  False  False  False      False   \n",
       "\n",
       "                                    mean  percentage of true  true  \n",
       "2018-08-17 00:00:00's next day  0.489114                 0.1  0.00  \n",
       "2018-08-16 00:00:00's next day  0.540150                 0.1 -0.39  \n",
       "2018-08-14 00:00:00's next day  0.789027                 0.3  0.00  \n",
       "2018-08-13 00:00:00's next day  1.265923                 0.8  2.82  \n",
       "2018-08-10 00:00:00's next day  0.947321                 0.8 -3.12  \n",
       "2018-08-09 00:00:00's next day  0.853119                 0.3  1.99  \n",
       "2018-08-08 00:00:00's next day -0.074718                 0.1  5.46  \n",
       "2018-08-07 00:00:00's next day  0.286577                 0.3 -0.83  \n",
       "2018-08-06 00:00:00's next day -0.059702                 0.4  5.73  \n",
       "2018-08-03 00:00:00's next day  0.040638                 0.0  0.44  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the value's standard is % based on today's stock price.\n",
    "# True = tomorrow gonna be +, positive return\n",
    "# False = negative.\n",
    "# 'true' column is actual result.\n",
    "#recent 'true' is defalut zero because we do not have tomorrow's actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
